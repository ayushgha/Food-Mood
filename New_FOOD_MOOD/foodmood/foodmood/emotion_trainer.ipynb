{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1ebdfbc7169be6564e12fd9b68cbdcf40ac08f3"
   },
   "source": [
    "**CNN Trainer on Kaggle Challenge -- Challenges in Representation Learning: Facial Expression Recognition Challenge**\n",
    "\n",
    "**Author:** Shashi Kant\n",
    "\n",
    "**Date:** 05/12/2018\n",
    "\n",
    "**Accuracy Achieved on Test Data:** 65.34 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "data = pd.read_csv('data/fer2013.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5454b38cd7695f5f58b0c3ff9a9479b8dff19e95"
   },
   "outputs": [],
   "source": [
    "# Taking Training and PublicTest data for training and PrivateTest data for testing\n",
    "data_train = data[:32298]\n",
    "data_test = data[32298:]\n",
    "# data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8a3e0e6cc0718a4c3ad0bc2ffd2200b76d815982"
   },
   "outputs": [],
   "source": [
    "y_train = data_train['emotion'].values\n",
    "y_test = data_test['emotion'].values\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e2ec87a5283757643b796bd18b2225a3d2b63158"
   },
   "outputs": [],
   "source": [
    "# Converting string of pixel data to an array\n",
    "x_train = np.zeros((y_train.shape[0], 48*48))\n",
    "for i in range(y_train.shape[0]):\n",
    "    x_train[i] = np.fromstring(data_train['pixels'][i], dtype=int, sep=' ')\n",
    "    \n",
    "x_test = np.zeros((y_test.shape[0], 48*48))\n",
    "for i in range(y_test.shape[0]):\n",
    "    x_test[i] = np.fromstring(data_test['pixels'][32298+i], dtype=int, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "151b21bdb369afed666fc28eedbe765e74253cc1"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ddd5fbcabd7397da281ba451eb566375f8d1768a"
   },
   "outputs": [],
   "source": [
    "# Generate reversed images for every data assuming emotion are symetric\n",
    "img_rows, img_cols = 48, 48\n",
    "num_classes = 7\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "x_train_rev = np.flip(x_train, 2)\n",
    "x_test_rev = np.flip(x_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "538a35482d75a9838009399707075fa2f6f0c1e4"
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.imshow(x_train[0].reshape((48,48)))\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(x_train_rev[0].reshape((48,48)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e38772aa2e4388f5e0f35559be3a31b2210b317a"
   },
   "outputs": [],
   "source": [
    "# Some preprocessing\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train_rev = x_train_rev.astype('float32')\n",
    "x_test_rev = x_test_rev.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_train_rev /= 255\n",
    "x_test_rev /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2723bc36ac000c54eec8b30a35760065da9bb93d"
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    # model.add(Conv2D(32, (3, 3)))\n",
    "    # model.add(BatchNormalization())\n",
    "    # model.add(Activation('relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b65dce0e4536065c10e41375b0f07ce11e91f3b9"
   },
   "outputs": [],
   "source": [
    "# function to plot graph\n",
    "def plotGraph(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aca43613dff945317a18394758171af94db2cc94"
   },
   "source": [
    "**We will train two models one on normal images another on reversed images and finally a NN on predicted values from these models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "182ccbd83d23e518bc8d7732ab15ae31bbaea43b"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 25\n",
    "model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f3d2e0e8e19bc804b223a0a9fa6c8ba476244a5"
   },
   "outputs": [],
   "source": [
    "print(\"=======| Model 1 |=========\")\n",
    "modelc = cnn_model()\n",
    "history = modelc.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split = 0.1)\n",
    "model.append(modelc)\n",
    "plotGraph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46b701637374e54460397ada95a497c8615a92d9"
   },
   "outputs": [],
   "source": [
    "print(\"=======| Model 2 |=========\")\n",
    "modelc = cnn_model()\n",
    "history = modelc.fit(x_train_rev, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_split = 0.1)\n",
    "model.append(modelc)\n",
    "plotGraph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "13b989271ef1e85c9342d2ea02661619e88dcab6"
   },
   "outputs": [],
   "source": [
    "# p_tr >> prediction on training data\n",
    "# p_te >> prediction on test data\n",
    "\n",
    "p_tr = []\n",
    "p_te = []\n",
    "\n",
    "for i, m in enumerate(model):\n",
    "    if i ==0:\n",
    "        p = m.predict(x_train)\n",
    "        pt = m.predict(x_test)\n",
    "    else:\n",
    "        p = m.predict(x_train_rev)\n",
    "        pt = m.predict(x_test_rev)\n",
    "    p_tr.append(p)\n",
    "    p_te.append(pt)\n",
    "    m.save('saved_model/cnn'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4754e6348465dbad0dd2e13689f1bd44ff9821f2"
   },
   "outputs": [],
   "source": [
    "print(len(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b6133e3cefd35fae4f48cb5a035f40b313291ca"
   },
   "outputs": [],
   "source": [
    "p_train = np.zeros((y_train.shape[0],num_classes*len(model)))\n",
    "p_test = np.zeros((y_test.shape[0],num_classes*len(model)))\n",
    "for i, p in enumerate(p_tr):\n",
    "    print(i)\n",
    "    p_train[:,num_classes*i:num_classes*(i+1)] = p\n",
    "\n",
    "for i, p in enumerate(p_te):\n",
    "    p_test[:,num_classes*i:num_classes*(i+1)] = p\n",
    "    \n",
    "print(p_train.shape, p_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f6bfdf155bbfe4cd21200a81219e0350695502a"
   },
   "outputs": [],
   "source": [
    "# Trains an Conventional Neural Network on previously predicted values by the two models\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 7\n",
    "epochs = 3\n",
    "\n",
    "modele = Sequential()\n",
    "modele.add(Dense(128, activation='relu', input_shape=(num_classes*len(model),)))\n",
    "modele.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "modele.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = modele.fit(p_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(p_test, y_test))\n",
    "          \n",
    "score = modele.evaluate(p_test, y_test, verbose=0)\n",
    "modele.save('saved_model/ensemble.h5')\n",
    "\n",
    "print('NN Based Ensembled Model')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6622b79757587a9684fb51ed4cec6bda9ada515c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
